[What is binary search?]

root cause of a problem: looking for one answer in a list of many. 
Goal: Searching for an element in a list 
list of algorithms:
    linear search:  
        method: start from the first entry and then check if the name is the one that we're looking for. If it doesn't match, move to the second element and check again, and keep going until we find the employee with the name we're looking for, or we get to the end of the list. 
        time: proportional to the length of the list. 1000 items can equal 1000 comparisions.
        when to use: works for shorter files.
     binary search: 
        method: 1. Sort the list
                2. compare the name that we're looking for with the element in the middle of the list and check if it's equal, smaller, or bigger. 
                3. smaller, look in the first half of the list. 
                4. bigger, we know that it's in the second half of the list. 
                5. Each time we look at the middle element of the section we're dealing with, until we find the element we're looking for. 
        time: 1,000 comparisions can equal 10 comparisons. 
        when: This is calculated as the base two logarithm of the lists length, and the benefits get more and more significant the longer the list. 

[Linear and Binary Search (Optional)]

def linear_search(list, key):
    """If key is in the list returns its position in the list,
       otherwise returns -1."""
    for i, item in enumerate(list):
        if item == key:
            return i
    return -1

def binary_search(list, key):
    """Returns the position of key in the list if found, -1 otherwise.

    List must be sorted.
    """
    left = 0
    right = len(list) - 1
    while left <= right:
        middle = (left + right) // 2
        
        if list[middle] == key:
            return middle
        if list[middle] > key:
            right = middle - 1
        if list[middle] < key:
            left = middle + 1
    return -1

[Applying Binary Search in Troubleshooting]

In troubleshooting, we can apply this idea when we need to go through and test a long list of hypotheses. 

The list of elements could be entries in a file, extensions enabled, boards connected to a server, or even lines of code added to a faulty release. 

A.K.A.: bisecting which means dividing in two. 

Problem: program that fail to start when the old configuration directory was present. 
Configuration: create a copy of the directory with just 1/2 of config files and then try to start the program again. If it crashes, then the bad file is among the first half tested. If it doesn't, it's among the other half not tested. In the next step, we would pick 1/2 of the failing group. If the program crashes again, it's one of those files. If it doesn't, it's one of the other group of files. For the last three, we can first check two together or just go one by one. Either way, it's two checks to get to the failing file. (example) This means that with a total of four attempts (12 files), we can find out which of the 12 files is causing the problem. 


               verify that the program crashes with that single file present and doesn't crash when the single file isn't present. Once we've confirmed that, we've reduced the reproduction case of our problem to a single file instead of a whole directory much easier to understand and figure out what's going on. 
               
               After that, we can proceed in the same way with the contents of that single file, cutting it in half repeatedly, until we find the specific part of the file that's causing the problem. 

Problem: browser extension is causing the browser to crash
Solution: disabling half of the extensions then checking if the browser crashes with that subset and so on until we find the faulty extension. 

Problem: plug-in in a desktop environment is causing the computer to run out of memory
Problem: which entry in a database is causing the program to raise an exception. 

Problem: a bug that was introduced in a recent version. 
Solution: If we know the list of changes that were made between one version and the next, we can keep cutting that list in half until we find the one that caused the failure. 
[Git command: bisect.] Bisect receives two points in time in the Git history and repeatedly lets us try the code at the middle point between them until we find the commit that caused the breakage. This doesn't even need to be your Git repository. 

If you're using open source software that's tracking Git, you can use the bisect commit to find out which command cause the software to stop working on your computer. For example, if the latest release of the Linux kernel causes the sound card on your computer to stop working, you can use Git bisect to find the commit that broke it and report this as a bug to be fixed. As we called out when we were talking about binary search, the longer the list of items that needs to be checked, the more we'll gain by cutting our problem in half on each iteration. If it's just five options that need to be checked, we can simply go one-by-one. It won't make a lot of difference and it might be easier to keep track of what we tried. But if it's a 100, we definitely want to bisect the problem so we can find the answer in seven steps. Not a 100. When we have to test a bunch of different options to find the one that's causing a failure, we'll want a quick and easy way to check it. Even if we're reducing the amount of attempts by bisecting the problem, we don't want to spend a long time on each check. Sometimes it's straightforward. Either the program starts or it fails. But other times, it can take a bunch of manual steps to check what we want to check. So depending on what the problem is that we're trying to find, it might make sense to spend some time creating a script that checks for the issue. Up next, we'll see this in action in a practical example

[Finding Invalid Data]

We have discussed how we can quickly find out the reason for a problem in a list of possible reasons by splitting the problem in half and testing each half separately. Let's see this in action with an example. We have a program that reads data from a CSV file, processes it, and then imports it into a database. One of the users of the system tells us that the file they're trying to import fails with an obscure import error. They've sent us the file so we can try it ourselves. To call the command, we'll connect the output of cat contacts.csv, the file that the user sent us, to the import.py command. But before we run the command, it's a good time to remember that we shouldn't test in production. And since this script is going to be trying to import data into a database, we should run it against the test database instead of the production database. To do that, we'll use the --server flag that takes the name of the database server, and then we'll pass the test as the parameter.

We see that the file fails with an importing error, and doesn't give us a lot of information about what's failing. And how big is that file? We could open it with an editor and check, but we don't need to. We can use the wc command that counts characters, words, and lines in a file. 

[wc -l] will print the amount of lines in a file.

So our file has 100 lines in it, that's a lot. We don't want to have to go looking through that list to find out what could be wrong, especially since we have no idea what that might be. 

Solution: try passing only half of the file to the script and check if it succeeds or fails. If it fails, then we pick up that part of the file and check again with half of it.

If our import succeeds, then we take the other half and split it in two. We could edit the file manually to add or remove the parts as needed, but that would be tedious. Instead, we can use the tools available to us to help us do that with less effort. 

[head command] to print the first lines in the file
[tail command] to print the last lines. 

We can pass the amount of lines we want to include as a parameter. 
[head -15] will print the first 15 lines, while 
[tail -20] will print the last 20 lines. Okay, 
our command reads the file to import from standard input.  use pipes to connect the output of our head or tail commands to it. 

First half

Okay, so the first half failed, let's split it again. To do that, we'll use another pipe to take only half of the previous number. This way, in each step, we'll add a call to head or tail for the corresponding size.

This time, it succeeded, hooray. This means that the failure must be in the second quarter of the file. Let's verify that that's the case by giving that part to our command. To do that, we'll take the first half using head, then get the second half of it using tail.
This fails again, but that's good, it means we're on the right track. Let's split it once again.

Great, our test set is getting smaller, let's split it once more.

Okay, we're down to six entries, and we know that one of them is the bad one. Let's spin it one more time, and then we can look at the three remaining entries.

All right, let's look at the three entries left and see if we can find the culprit.

Can you see the problem? This is a comma separated file. This means that each comma is used as a separator between the fields in the file. If a field includes commas, it should be written between quotes. But in the case of the third line we're looking at here, we can see that there's a comma instead of a period after the middle initial, and this is not written between quotes. The importing script is then confused because there are too many fields in this line. Okay, let's edit the file and fix it.

And now let's run our importer again with the fixed file.

Yay, we fixed the problem in the file. Using the bisect method, we very quickly found which line out of 100 lines contained the corrupt data. And then we could fix it and successfully import it. The short-term remediation here is to tell our user about what we found and how to fix it, so that they can import the data into the production database. The long-term remediation is to figure out why the file was generated with the invalid field in the first place, and make sure that it doesn't happen again. Coming up, another practice quiz to help put your bisecting knowledge into action.
