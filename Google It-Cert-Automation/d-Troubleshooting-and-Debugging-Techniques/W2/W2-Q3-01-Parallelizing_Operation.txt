[There's actually a whole field of computer science called concurrency, dedicated to how we write programs that do operations in parallel.]
[Our OS handles the many processes that run on our computer.]
[more than one core, the operating system can decide which processes get executed on which core,]
[all of these processes will be executing in parallel.]
[Each of them has its own memory allocation and does its own IO calls.]
[OS will decide what fraction of CPU time each process gets]
[collect statistics on the current load and memory usage for all the computers in your network.]
[script that connects to each computer in a list and gets the stats.]
[split the list of computers into smaller groups and use the OS to call the script many times once for each group.]
[the connections to the different computers can be started in parallel, which minimizes the time but the CPU isn't doing anything.]
[good balance of different workloads that you run on a computer.]
[process that's using a lot of CPU while a different process is using a lot of network IO and another process is using a lot of disk IO, these can all run in parallel without interfering with each other.]
[OS to split the work and the processes, these processes don't share any memory, and sometimes we might need to have some shared data.]
[use threads.]
[Threads let us run parallel tasks inside a process.]
[to share some of the memory with other threads in the same process.]
[modify our code to create and handle the threads.]
[In Python, we can use the Threading or AsyncIO modules to do this.]
[specify which parts of the code we want to run in separate threads or as separate asynchronous events, and how we want the results of each to be combined in the end.]
[if you want to use more processors, you'll need to split the code into fully separate processes.]
[In other words, your script is CPU bound.]
[split your execution across processors.]
[If we're trying to read a bunch of files from disk and do too many operations in parallel, the disk might end up spending more time going from one position to another then actually retrieving the data, or if we're doing a ton of operations that use a lot of CPU, the OS could spend more time switching between them than actually making progress in the calculations we're trying to do.]
