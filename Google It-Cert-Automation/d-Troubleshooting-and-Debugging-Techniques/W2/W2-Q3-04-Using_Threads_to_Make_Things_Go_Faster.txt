We only touched briefly on the ways we can use concurrency to improve our programs. If you're interested in learning more, this article from Real Python has a lot of details on the different ways to use concurrency in Python.

Check out the following links for more information:

[Python-concurrency]
https://realpython.com/python-concurrency/

So far, you’ve looked at concurrency that happens on a single processor.
Concurrence: concurrency is simultaneous occurrence.  (thread, task, process) - high level, they all refer to a sequence of instructions that run in order.

only multiprocessing actually runs these trains of thought at literally the same time. Threading and asyncio both run on a single processor and therefore only run one at a time. They just cleverly find ways to take turns to speed up the overall process. Even though they don’t run different trains of thought simultaneously, we still call this concurrency.

 take turns is the big difference between threading and asyncio. In [threading], the operating system actually knows about each thread and can interrupt it at any time to start running a different thread. This is called pre-emptive multitasking since the operating system can pre-empt your thread to make the switch.

Pre-emptive multitasking is handy in that the [code in the thread doesn’t need to do anything to make the switch]. It can also be difficult because of that “at any time” phrase. This switch can happen in the middle of a single Python statement, even a trivial one like x = x + 1.

[Asyncio], on the other hand, uses [cooperative multitasking]. The tasks must cooperate by announcing when they are ready to be switched out. That means that the code in the task has to change slightly to make this happen.

The benefit of doing this extra work up front is that [you always know where your task will be swapped out]. It will not be swapped out in the middle of a Python statement unless that statement is marked. You’ll see later how this can simplify parts of your design.

Parallelism:  [What about all of those CPU cores your cool, new laptop has? How can you make use of them? multiprocessing] is the answer.

With multiprocessing, Python creates new processes. A process here can be thought of as almost a completely different program, though technically they’re usually defined as a collection of resources where the resources include memory, file handles and things like that. One way to think about it is that each process runs in its own Python interpreter.

Because they are different processes, each of your trains of thought in a multiprocessing program can run on a different core. Running on a different core means that they actually can run at the same time, which is fabulous. There are some complications that arise from doing this, but Python does a pretty good job of smoothing them over most of the time.

Now that you have an idea of what concurrency and parallelism are, let’s review their differences, and then we can look at why they can be useful:

Concurrency Type 	                    Switching Decision 	                                                    Number of Processors
Pre-emptive multitasking (threading) 	The operating system decides when to switch tasks external to Python. 	1
Cooperative multitasking (asyncio) 	    The tasks decide when to give up control. 	                            1
Multiprocessing (multiprocessing) 	    The processes all run at the same time on different processors. 	    Many


Concurrency can make a big difference for two types of problems. These are generally called CPU-bound and I/O-bound.

I/O-bound problems cause your program to slow down because it frequently must wait for input/output (I/O) from some external resource. They arise frequently when your program is working with things that are much slower than your CPU.

On the flip side, there are classes of programs that do significant computation without talking to the network or accessing a file. These are the CPU-bound programs, because the resource limiting the speed of your program is the CPU, not the network or the file system.

Adding concurrency to your program adds extra code and complications, so you’ll need to decide if the potential speed up is worth the extra effort.

Threaded-asynchronous magic!
https://hackernoon.com/threaded-asynchronous-magic-and-how-to-wield-it-bba9ed602c32

I/O-Bound Process 
Your program spends most of its time talking to a slow device, like a network connection, a hard drive, or a printer.
Speeding it up involves overlapping the times spent waiting for these devices. 	

CPU-Bound Process
You program spends most of its time doing CPU operations.
Speeding it up involves finding ways to do more computations in the same amount of time.


