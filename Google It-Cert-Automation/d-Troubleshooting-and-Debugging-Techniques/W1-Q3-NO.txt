What is binary search?

Usually when trying to find the root cause of a problem, we'll be looking for one answer in a list of many. Searching for an element in a list is a common problem in computing. There are a bunch of different algorithms that can help us find the element that we're looking for. Say for example, you have a list that contains the data of employees that work at your company and you want to find one specific employee. One possible approach would be to start from the first entry and then check if the name is the one that we're looking for. If it doesn't match, move to the second element and check again, and keep going until we find the employee with the name we're looking for, or we get to the end of the list. This is called a linear search. This type of search works but the longer the list, the longer it can take. In other words, the time it takes to find the result is proportional to the length of the list. If the list is sorted, we can use an alternative algorithm for searching called binary search. Because the list is sorted, we can make decisions about the position of the elements in the list. So the first thing we do is compare the name that we're looking for with the element in the middle of the list and check if it's equal, smaller, or bigger. If it's smaller, we know that the element we're looking for must be in the first half of the list. On the flip side, if it's bigger, we know that it's in the second half of the list. This way, with only one comparison, we've eliminated half of the list from possible candidates where the element could have been found, and then we do the same thing again and again until we find the element. So if the element we were looking for was smaller than the middle element, we look at the element in the middle of the first half. If our element is now bigger, we look at the element in the middle of the second quarter, and so on. Each time we look at the middle element of the section we're dealing with, until we find the element we're looking for. Using linear search, going through a list with 1000 elements might take up to 1,000 comparisons if the element we're looking for is the last one in the list or isn't present at all. Using binary search for the same list of 1,000 elements, the worst-case is only 10 comparisons. This is calculated as the base two logarithm of the lists length, and the benefits get more and more significant the longer the list. For a list of 100,000 elements, it would be 17 comparisons instead of 100,000 comparisons. But remember, that for this to work, the list needs to be sorted. So if the list isn't sorted, we would need a sort it first, which takes a chunk of time. It can still make sense to do it if we're going to search through it several times but it doesn't make sense to sort the list and then use binary search to only find one element. In that case, using linear search is simpler and faster. If you're curious about what these two types of search look like when implemented in Python, you can see a possible implementation of linear search and one for binary search in the next reading. After that, we'll talk about how we can apply the principles of binary search to troubleshooting.

Linear and Binary Search (Optional)

def linear_search(list, key):
    """If key is in the list returns its position in the list,
       otherwise returns -1."""
    for i, item in enumerate(list):
        if item == key:
            return i
    return -1

def binary_search(list, key):
    """Returns the position of key in the list if found, -1 otherwise.

    List must be sorted.
    """
    left = 0
    right = len(list) - 1
    while left <= right:
        middle = (left + right) // 2
        
        if list[middle] == key:
            return middle
        if list[middle] > key:
            right = middle - 1
        if list[middle] < key:
            left = middle + 1
    return -1

Applying Binary Search in Troubleshooting

We call that the binary search algorithm. It's really efficient when trying to find an element in a sorted list. In troubleshooting, we can apply this idea when we need to go through and test a long list of hypotheses. When doing this, the list of elements contains all the possible causes of the problem and we keep reducing the problem by half until only one option is left. The list of elements could be entries in a file, extensions enabled, boards connected to a server, or even lines of code added to a faulty release. With each iteration, the problem is cut in half. This approach is sometimes called bisecting which means dividing in two. In an earlier video, we gave the example of a new version of a program that fail to start when the old configuration directory was present. If the directory contained a bunch of different files in it, we could identify the one causing the failure by bisecting the list of files. Say the old directory contained 12 different config files. We want to identify which of those 12 is causing the failure. To do that, we can create a copy of the directory with just six of the 12 files and then try to start the program again. If it crashes, then the bad file is among those six files. If it doesn't, it's among the other six. In the next step, we would pick three out of the failing group of six. If the program crashes again, it's one of those three. If it doesn't, it's one of the other three. For the last three, we can first check two together or just go one by one. Either way, it's two checks to get to the failing file. This means that with a total of four attempts, we can find out which of the 12 files is causing the problem. Since things in IT can sometimes be complex and intertwined, before declaring victory, we want to verify that the program crashes with that single file present and doesn't crash when the single file isn't present. Once we've confirmed that, we've reduced the reproduction case of our problem to a single file instead of a whole directory much easier to understand and figure out what's going on. After that, we can proceed in the same way with the contents of that single file, cutting it in half repeatedly, until we find the specific part of the file that's causing the problem. The same process can be applied to a large variety of problems. It's very common for example to use it to figure out which browser extension is causing the browser to crash, disabling half of the extensions then checking if the browser crashes with that subset and so on until we find the faulty extension. We can also use this technique to discover which plug-in in a desktop environment is causing the computer to run out of memory, or which entry in a database is causing the program to raise an exception. We can also apply this to code when trying to find a bug that was introduced in a recent version. If we know the list of changes that were made between one version and the next, we can keep cutting that list in half until we find the one that caused the failure. When using Git for version control, we can use a Git command called bisect. Bisect receives two points in time in the Git history and repeatedly lets us try the code at the middle point between them until we find the commit that caused the breakage. This doesn't even need to be your Git repository. If you're using open source software that's tracking Git, you can use the bisect commit to find out which command cause the software to stop working on your computer. For example, if the latest release of the Linux kernel causes the sound card on your computer to stop working, you can use Git bisect to find the commit that broke it and report this as a bug to be fixed. As we called out when we were talking about binary search, the longer the list of items that needs to be checked, the more we'll gain by cutting our problem in half on each iteration. If it's just five options that need to be checked, we can simply go one-by-one. It won't make a lot of difference and it might be easier to keep track of what we tried. But if it's a 100, we definitely want to bisect the problem so we can find the answer in seven steps. Not a 100. When we have to test a bunch of different options to find the one that's causing a failure, we'll want a quick and easy way to check it. Even if we're reducing the amount of attempts by bisecting the problem, we don't want to spend a long time on each check. Sometimes it's straightforward. Either the program starts or it fails. But other times, it can take a bunch of manual steps to check what we want to check. So depending on what the problem is that we're trying to find, it might make sense to spend some time creating a script that checks for the issue. Up next, we'll see this in action in a practical example

Finding Invalid Data

We have discussed how we can quickly find out the reason for a problem in a list of possible reasons by splitting the problem in half and testing each half separately. Let's see this in action with an example. We have a program that reads data from a CSV file, processes it, and then imports it into a database. One of the users of the system tells us that the file they're trying to import fails with an obscure import error. They've sent us the file so we can try it ourselves. To call the command, we'll connect the output of cat contacts.csv, the file that the user sent us, to the import.py command. But before we run the command, it's a good time to remember that we shouldn't test in production. And since this script is going to be trying to import data into a database, we should run it against the test database instead of the production database. To do that, we'll use the --server flag that takes the name of the database server, and then we'll pass the test as the parameter.

We see that the file fails with an importing error, and doesn't give us a lot of information about what's failing. And how big is that file? We could open it with an editor and check, but we don't need to. We can use the wc command that counts characters, words, and lines in a file. In particular, wc -l will print the amount of lines in a file.
Play video starting at :1:43 and follow transcript1:43
So our file has 100 lines in it, that's a lot. We don't want to have to go looking through that list to find out what could be wrong, especially since we have no idea what that might be. Instead, we can try passing only half of the file to the script and check if it succeeds or fails. If it fails, then we pick up that part of the file and check again with half of it.
Play video starting at :2:7 and follow transcript2:07
If our import succeeds, then we take the other half and split it in two. We could edit the file manually to add or remove the parts as needed, but that would be tedious. Instead, we can use the tools available to us to help us do that with less effort. We can use the head command to print the first lines in the file, and the tail command to print the last lines. We can pass the amount of lines we want to include as a parameter. So head -15 will print the first 15 lines, while tail -20 will print the last 20 lines. Okay, and as we saw earlier, our command reads the file to import from standard input. So we can use pipes to connect the output of our head or tail commands to it. Let's try to input the first half of the file now.
Play video starting at :3:9 and follow transcript3:09
Okay, so the first half failed, let's split it again. To do that, we'll use another pipe to take only half of the previous number. This way, in each step, we'll add a call to head or tail for the corresponding size.
Play video starting at :3:36 and follow transcript3:36
This time, it succeeded, hooray. This means that the failure must be in the second quarter of the file. Let's verify that that's the case by giving that part to our command. To do that, we'll take the first half using head, then get the second half of it using tail.
Play video starting at :4:2 and follow transcript4:02 This fails again, but that's good, it means we're on the right track. Let's split it once again.
Play video starting at :4:17 and follow transcript4:17
Great, our test set is getting smaller, let's split it once more.
Play video starting at :4:42 and follow transcript4:42
Okay, we're down to six entries, and we know that one of them is the bad one. Let's spin it one more time, and then we can look at the three remaining entries.
Play video starting at :4:59 and follow transcript4:59
All right, let's look at the three entries left and see if we can find the culprit.
Play video starting at :5:13 and follow transcript5:13
Can you see the problem? This is a comma separated file. This means that each comma is used as a separator between the fields in the file. If a field includes commas, it should be written between quotes. But in the case of the third line we're looking at here, we can see that there's a comma instead of a period after the middle initial, and this is not written between quotes. The importing script is then confused because there are too many fields in this line. Okay, let's edit the file and fix it.
Play video starting at :6:8 and follow transcript6:08
And now let's run our importer again with the fixed file.
Play video starting at :6:20 and follow transcript6:20
Yay, we fixed the problem in the file. Using the bisect method, we very quickly found which line out of 100 lines contained the corrupt data. And then we could fix it and successfully import it. The short-term remediation here is to tell our user about what we found and how to fix it, so that they can import the data into the production database. The long-term remediation is to figure out why the file was generated with the invalid field in the first place, and make sure that it doesn't happen again. Coming up, another practice quiz to help put your bisecting knowledge into action.
