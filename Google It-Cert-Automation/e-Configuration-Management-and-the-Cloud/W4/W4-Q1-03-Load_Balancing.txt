[MUSIC]
[want more than one machine or container running our service.]
[ horizontally scale our service to handle more work, distribute instances geographically to get closer to our users.]
[backup instances to keep the service running if one or more of the instances fail.]
[use orchestration tools and techniques to make sure that the instances are repeatable.]
[replicated machines, we'll want to distribute the requests across instances.]
[load balancing comes into play.]
[round robin DNS.]
[Round robin is a really common method for distributing tasks.]
[gets one cookie.]
[give everyone a second serving ]
[until all of the treats are gone]
[translate a URL like my service.example.com into an IP address, we use the DNS protocol or domain name system.]
[Clients are served in turn.]
[he URL always gets translated into exactly the same IP address.]
[DNS to use round robin, it'll give each client asking for the translation a group of IP addresses in a different order.]
[clients will then pick one of the addresses]
[If an attempt fails, the client will jump to another address]
[First, you can't control which addresses get picked by the clients.]
[can't stop the clients from reaching out to it.]
[DNS records are cached by the clients and other servers.]
[change the list of addresses for the instances, you'll have to wait until all of the DNS records that were cached by the clients expire.]
[we can set up a server as a dedicated load balancer.]
[machine that acts as a proxy between the clients and the servers.]
[directs them to the selected back-end server.]
[Say your service needs to keep track of the actions that a user has taken up till now. In this case, you'll want your load balancer to use sticky sessions.]
[Using sticky sessions means all requests from the same client always go to the same back end server.]
[use it only if you really need it. Otherwise, you'll end up in a really sticky situation.]
[load balancers is that you can configure them to check the health of the backend servers.]
[If a back-end server is unhealthy, the load balancer will stop sending new requests to it to keep only healthy servers in the pool.]
[cool feature of cloud infrastructure is how easily we can add or remove machines from a pool of servers providing a service.]
[adding a new machine to the pool is as easy as creating the instance. And then letting the load balancer know that it can now route traffic to it.]
[manually creating and adding the instance or when our services under heavy load, we can just let the auto scaling feature do it.]
[make sure that clients connect to the servers that are closest to them?]
[use Geo DNS and GeoIP.]
[most Cloud providers offer it as part of their services making it much easier to have a geographically distributed service.]
[There are some providers dedicated to bringing the contents of your services as close to the user as possible. These are the content delivery networks or CDNs.]
[network of physical hosts that are geographically located as close to the end user as possible.]
[often in the same data center as the users Internet service provider.]
[caching content super close to the user.]
[When a user requests say, a cute cat video, it's stored in the closest CDN server. That way, when a second user in the same region requests the same cat video, it's already cached in a server that's pretty close and it can be downloaded extra fast.]
