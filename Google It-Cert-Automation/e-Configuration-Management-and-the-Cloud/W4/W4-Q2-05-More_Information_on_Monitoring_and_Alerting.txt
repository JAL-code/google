[having monitoring data is a necessary condition for observability into the inner workings of your systems]
[which data to collect, and how to classify that data]
[Collecting data is cheap, but not having it when you need it can be expensive, so you should instrument everything, and collect all the useful data you reasonably can.]
[Metrics capture a value pertaining to your systems at a specific point in time ]
[or example, the number of users currently logged in to a web application. Therefore, metrics are usually collected once per second, one per minute, or at another regular interval to monitor a system over time.]
[WORK - Throughput, success, error, performance]
[throughput is the amount of work the system is doing per unit time. Throughput is usually recorded as an absolute number.]
[ success metrics represent the percentage of work that was executed successfully.]
[error metrics capture the number of erroneous results, usually expressed as a rate of errors per unit time or normalized by the throughput to yield errors per unit of work. Error metrics are often captured separately from success metrics when there are several potential sources of error, some of which are more serious or actionable than others.]
[RESOURCES - Utilization, saturation, error, availability.]
[saturation is a measure of the amount of requested work that the resource cannot yet service, often queued.]
[errors represent internal errors that may not be observable in the work the resource produces.]
[availability represents the percentage of time that the resource responded to requests. This metric is only well-defined for resources that can be actively and regularly checked for availability.]
[EVENTS - Code changes, alerts, scaling, "high demand service"]
[Changes: Internal code releases, builds, and build failures]
[Alerts: Internally generated alerts or third-party notifications]
[Scaling events: Adding or subtracting hosts]
[Events capture what happened, at a point in time, with optional additional information. ]
[metrics are incredibly important for observability. ]
[Good metrics are:]
[Tagged by scope. Each of your hosts operates simultaneously in multiple scopes, and you may want to check on the aggregate health of any of these scopes, or their combinations. For example: how is production doing in aggregate? How about production in the Northeast U.S.? How about a particular role or service? It is important to retain the multiple scopes associated with your data so that you can alert on problems from any scope, and quickly investigate outages without being limited by a fixed hierarchy of hosts.]
[Metrics, monitoring, and alerting are all interrelated concepts that together form the basis of a monitoring system. ]
[If the metrics fall outside of your expected ranges, these systems can send notifications to prompt an operator to take a look, and can then assist in surfacing information to help identify the possible causes.]
[Metrics represent the raw measurements of resource usage or behavior that can be observed and collected throughout your systems. ]
[easiest metrics to begin with are those already exposed by your operating system to represent the usage of underlying physical resources. Example - disk space, CPU load, swap usage, etc.]
[add code or interfaces to expose the metrics you care about. Collecting and exposing metrics is sometimes known as adding instrumentation to your services.]
[ difference between metrics and monitoring mirrors the difference between data and information. ]
[ Data is composed of raw, unprocessed facts, while information is produced by analyzing and organizing data to build context that provides value.]
[Secondly, monitoring systems typically provide visualizations of data.]
[Monitoring systems functions:]
[Their first responsibility is to accept and store incoming and historical data.]
[Monitoring systems usually represent the components they measure with configurable graphs and dashboards.]
[monitoring systems provide is organizing and correlating data from various inputs.]
[Alerting is the responsive component of a monitoring system that performs actions based on changes in metric values. Alerts definitions are composed of two components: a metrics-based condition or threshold, and an action to perform when the values fall outside of the acceptable conditions.]
[However, the main purpose of alerting is still to bring human attention to bear on the current status of your systems.]
[Host-Based Metrics]
[These would be anything involved in evaluating the health or performance of an individual machine, disregarding for the moment its application stacks and services. These are mainly comprised of usage or performance of the operating system or hardware, like:      CPU     Memory     Disk space     Processes]
[application metrics: units of processing or work that depend on the host-level resources, like services or applications. The specific types of metrics to look at depends on what the service is providing, what dependencies it has, and what other components it interacts with. Metrics at this level are indicators of the health, performance, or load of an application:      Error and success rates     Service failures and restarts     Performance and latency of responses     Resource usage]
[When dealing with horizontally scaled infrastructure, another layer of infrastructure you will need to add metrics for is pools of servers. While metrics about individual servers are useful, at scale a service is better represented as the ability of a collection of machines to perform work and respond adequately to requests. This type of metric is in many ways just a higher level extrapolation of application and server metrics, but the resources in this case are homogeneous servers instead of machine-level components. Some data you might want to track are:      Pooled resource usage     Scaling adjustment indicators     Degraded instances]
[Factors That Affect What You Choose to Monitor  For peace of mind, in an ideal world you would track everything related to your systems from the beginning in case an item may one day be relevant to you. However, there are many reasons why this might not be possible or even desirable.  A few factors that can affect what you choose to collect and act on are:      Resources available for tracking: Depending on your human resources, infrastructure, and budget, you will have to limit the scope of what you keep track of to what you can afford to implement and reasonably manage.     The complexity and purpose of your application: The complexity of your application or systems can have a large impact on what you choose to track. Items that might be mission critical for some software might not be important at all in others.     The deployment environment: While robust monitoring is most important for production systems, staging and testing systems also benefit from monitoring, though there may be differences in severity, granularity, and the overall metrics measured.     The likelihood of the metric being useful: One of the most important factors affecting whether something is measured is its potential to help in the future. Each additional metric tracked increases the complexity of the system and takes up resources. The necessity of data can change over time as well, requiring reevaluation at regular intervals.     How essential stability is: Simply put, stability and uptime might not be priorities for certain types of personal or early stage projects.]
[Important Qualities of a Metrics, Monitoring, and Alerting System:]
[Independent from Most Other Infrastructure - external to other services.]
[reliability. you can trust it to operate correctly on a daily basis.]
[Easy to Use Summary and Detail Views - is useful and consumable to human operators. ]
[Equally important is the ability to drill down from within summary displays to surface the information most pertinent to the current task. Dynamically adjusting the scale of graphs, toggling off unnecessary metrics, and overlaying information from multiple systems is essential to make the tool useful interactively for investigations or root cause analysis.]
[Effective Strategy for Maintaining Historical Data - help establish trends, patterns, and consistencies over long timelines.]
[ability to easily import existing data sets. If reducing the information density of your historic metrics is not an attractive option, offloading older data to a long-term storage solution might be a better alternative.]
[to display related information, even if it comes from different systems or has different characteristics.]
[need to be able to make adjustments as the machines and infrastructure change.]
[ease in which the monitoring system can be set up to track entirely new metrics.]
[evaluate is its alerting capabilities: need to be flexible enough to notify operators through multiple mediums and powerful enough to be able to compose thoughtful, actionable notification triggers. Many systems defer the responsibility of actually delivering notifications to other parties by offering integrations with existing paging services or messenger applications. This minimizes the responsibility of the alerting functionality and usually provides more flexible options since the plugin just needs to consume an external API.]
[cannot defer, however, is defining the alerting parameters. Alerts are defined based on values falling outside of acceptable ranges. some nuance in order to avoid over alerting. For instance, momentary spikes are often not a concern, but sustained elevated load may require operator attention.]
[Observability: Although not strictly defined, observability is a general term used to describe processes and techniques related to increasing awareness and visibility into systems. This can include monitoring, metrics, visualization, tracing, and log analAlerting is the responsive component of a monitoring system that performs actions based on changes in metric values. Alerts definitions are composed of two components: a metrics-based condition or threshold, and an action to perform when the values fall outside of the acceptable conditions.ysis.]
[Resource: In the context of monitoring and software systems, a resource is any exhaustible or limited dependency. What is considered a resource can vary greatly based on part of the system being discussed.]
[Latency: Latency is a measure of the time it takes to complete an action. Depending on the component, this can be a measure of processing, response, or travel time.]
[Throughput: Throughput represents the maximum rate of processing or traversal that a system can handle. This can be dependent on software or hardware design. Often there is an important distinction between theoretical throughput and practical observed throughput.]
[ Performance: Performance is a general measure of how efficiently a system is completing work. Performance is an umbrella term that often encompasses work factors like throughput, latency, or resource consumption.]
[Visualization: Visualization is the process of presenting metrics data in a format that allows for quick, intuitive interpretation through graphs or charts.]
[Log aggregation: Log aggregation is the act of compiling, organizing, and indexing log files to allow for easier management, searching, and analysis. While separate from monitoring, aggregated logs can be used in conjunction with the monitoring system to identify causes and investigate failures.]
[Data point: A data point is a single measurement of a single metric.]
[Data set: A data set is a collection of data points for a metric.]
[Units: Units are the context for a measured value. A unit defines the magnitude, scope, or quantity of a measurement to understand extent and allow comparison.]
[Percentage Units: Percentage units are measurements that are taken as a part of a finite whole. A percentage unit indicates how much a value is out of the total possible amount.]
[Rate Units: Rate units indicate the magnitude of a metric over a constant period of time.]
[Time series: Time series data is a series of data points that represent changes over time. Most metrics are best represented by a time series because single data points often represent a value at a specific time and the resulting series of points is used to show changes over time.]
[Sampling rate: Sample rate is a measurement of how often a representative data point is collected in lieu of continuous collection. A higher sampling rate more accurately represents the measured behavior, but requires more resources to handle the extra data points.]
[Resolution: Resolution refers to the density of data points that make up a data set. Collections with higher resolutions over the same time frame indicate a higher sample rate and a more granular view of the same behavior.]
[Instrumentation: Instrumentation is the ability to track the behavior and performance of software. This is accomplished by adding code and configuration to software to output data that can then be consumed by a monitoring system.]
[The observer effect: The observer effect is the impact of the monitoring system itself on the phenomena being observed. Since monitoring takes up resources, the act of measuring behavior and performance will alter the values produced. Monitoring systems seek to avoid adding unnecessary overhead to minimize this impact.]
[Over-monitoring: Over-monitoring occurs when the quantity of metrics and alerts configured is inversely related to their usefulness. Over-monitoring can cause stress on the infrastructure, make it difficult to find relevant data, and cause teams to lose trust in their monitoring and alerting systems.]
[Alert fatigue: Alert fatigue is the human response of desensitivity that results from frequent, unreliable, or improperly prioritized alerts. Alert fatigue can cause operators to ignore severe problems and is usually an indication that alert conditions need to be reevaluated.]
[Threshold: When alerting, a threshold is the boundary between acceptable and unacceptable values which triggers an alert if exceeded. Often alerts are configured to trigger when a value exceeds the threshold for a certain period of time, in order to avoid sending an alert for temporary spikes.]
[Trend: A trend is the general direction that a set of values is indicating. Trends are more reliable than single values in determining the general state of the component being tracked.]
[White-box monitoring: White-box monitoring is a term used to describe monitoring that relies on access to internal state of the components being measured. White-box monitoring can provide a detailed understanding of system state and is helpful for identifying causes of problems.]
